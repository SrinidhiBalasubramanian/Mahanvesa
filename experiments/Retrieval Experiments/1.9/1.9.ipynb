{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1tYynKnQvLJPnznJUOM3blaEvPO6wYDQE","authorship_tag":"ABX9TyOLHNY9mLZQFcJbAC7Dakm7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bow5Hs1-yPnz","executionInfo":{"status":"ok","timestamp":1762969469076,"user_tz":-330,"elapsed":506,"user":{"displayName":"Srinidhi","userId":"02160519943100045251"}},"outputId":"b1db7e89-a7b3-4f93-83b3-0b39d7ecd8fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/GenAI Project\n"]}],"source":["cd /content/drive/MyDrive/GenAI Project/"]},{"cell_type":"code","source":["import json\n","\n","def read_json(filepath):\n","    \"\"\"Reads a JSON file and returns the data.\"\"\"\n","    with open(filepath, 'r') as f:\n","        return json.load(f)\n","\n","def write_json(data, filepath):\n","    \"\"\"Writes data to a JSON file.\"\"\"\n","    with open(filepath, 'w') as f:\n","        json.dump(data, f, indent=4)"],"metadata":{"id":"VcB1rz_2zXh0","executionInfo":{"status":"ok","timestamp":1762969469077,"user_tz":-330,"elapsed":12,"user":{"displayName":"Srinidhi","userId":"02160519943100045251"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["mahabharata_questions =  read_json('Dataset/Test/questions.json')\n","itihasa_data = read_json('Dataset/Validation/final_data.json')"],"metadata":{"id":"o4pAa71szYyE","executionInfo":{"status":"ok","timestamp":1762969484209,"user_tz":-330,"elapsed":1598,"user":{"displayName":"Srinidhi","userId":"02160519943100045251"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!pip install sentence-transformers faiss-cpu tqdm\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"YG9LjHkHzinU","executionInfo":{"status":"ok","timestamp":1762969482610,"user_tz":-330,"elapsed":13543,"user":{"displayName":"Srinidhi","userId":"02160519943100045251"}},"outputId":"9fecb4ce-0710-4b26-e31b-83767c121c6b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n","Collecting faiss-cpu\n","  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n","Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.10.5)\n","Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.12.0\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModel\n","import torch\n","import numpy as np\n","from tqdm import tqdm\n","\n","# Load fine-tuned model\n","model_path = \"Retrieval Experiments/1.9/epoch_1\"\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","encoder = AutoModel.from_pretrained(model_path).to(device)\n","\n","# Convert texts to embeddings\n","doc_ids = list(itihasa_data.keys())\n","texts = list(itihasa_data.values())\n","\n","all_embeddings = []\n","\n","encoder.eval()\n","with torch.no_grad():\n","    for i in tqdm(range(0, len(texts), 32), desc=\"Encoding documents\"):\n","        batch_texts = texts[i:i+32]\n","        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n","        outputs = encoder(**inputs)\n","        # Mean pooling\n","        emb = outputs.last_hidden_state.mean(dim=1)\n","        # Normalize\n","        emb = torch.nn.functional.normalize(emb, p=2, dim=1)\n","        all_embeddings.append(emb.cpu().numpy())\n","\n","# Stack all batches\n","embeddings = np.vstack(all_embeddings)\n","\n","# Save embeddings and IDs\n","np.save(\"Retrieval Experiments/1.9/embeddings_manual_mpnet_1.npy\", embeddings)\n","\n","print(\"✅ Saved embeddings:\", embeddings.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hN7VfDSF0j9A","executionInfo":{"status":"ok","timestamp":1762878943768,"user_tz":-330,"elapsed":139790,"user":{"displayName":"Srinidhi","userId":"02160519943100045251"}},"outputId":"eb3a497f-111c-45b5-c287-d3ed65f3547d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Encoding documents: 100%|██████████| 66/66 [01:27<00:00,  1.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["✅ Saved embeddings: (2108, 768)\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModel\n","import torch\n","import numpy as np\n","import faiss\n","from tqdm import tqdm\n","import json\n","import pickle\n","import pandas as pd\n","\n","class EmbeddingSearchEvaluator:\n","    def __init__(self,\n","                 model_path=\"Retrieval Experiments/1.9/epoch_1\",\n","                 emb_path=\"Retrieval Experiments/1.9/embeddings_manual_mpnet_1.npy\",\n","                 ids_path=\"retrieval_modules_testing/embedding_models/doc_ids.pkl\"):\n","        # Load fine-tuned model\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n","        self.encoder = AutoModel.from_pretrained(model_path).to(self.device)\n","        self.encoder.eval()\n","\n","        # Load embeddings and IDs\n","        self.embeddings = np.load(emb_path)\n","        with open(ids_path, \"rb\") as f:\n","            self.doc_ids = pickle.load(f)\n","        print(f\"✅ Loaded {len(self.embeddings)} embeddings.\")\n","\n","        # Normalize (if not already)\n","        faiss.normalize_L2(self.embeddings)\n","\n","        # Build FAISS index\n","        dim = self.embeddings.shape[1]\n","        self.index = faiss.IndexFlatIP(dim)\n","        self.index.add(self.embeddings)\n","\n","    def _encode_query(self, text):\n","        \"\"\"Encode and normalize a single query string.\"\"\"\n","        inputs = self.tokenizer([text], return_tensors=\"pt\", truncation=True, padding=True).to(self.device)\n","        with torch.no_grad():\n","            outputs = self.encoder(**inputs)\n","            emb = outputs.last_hidden_state.mean(dim=1)\n","            emb = torch.nn.functional.normalize(emb, p=2, dim=1)\n","        return emb.cpu().numpy()\n","\n","    def evaluate_full_scores(self, questions_dict):\n","        results = {}\n","\n","        for q_id, q in tqdm(questions_dict.items(), desc=\"Evaluating questions\"):\n","                # Encode query and normalize\n","                query_vec = self._encode_query(q['question'])\n","                D, I = self.index.search(query_vec, k=len(self.doc_ids))\n","                scores = D[0]\n","                ids = [self.doc_ids[i] for i in I[0]]\n","                results[q_id] = {doc_id: float(score) for doc_id, score in zip(ids, scores)}\n","\n","        self.full_scores = results\n","        return results\n","\n","    def save_full_scores(self, path=\"Retrieval Experiments/1.9/embedding_scores_1.json\"):\n","        if not hasattr(self, \"full_scores\"):\n","            raise ValueError(\"Run evaluate_full_scores() first.\")\n","        with open(path, \"w\", encoding=\"utf-8\") as f:\n","            json.dump(self.full_scores, f, indent=4, ensure_ascii=False)\n","        print(f\"✅ Saved question–chapter scores to {path}\")\n","\n","    def search(self, query, top_k=3):\n","        \"\"\"Search for top_k most similar documents for a query string.\"\"\"\n","        query_vec = self.model.encode([query], convert_to_numpy=True)\n","        faiss.normalize_L2(query_vec)\n","        D, I = self.index.search(query_vec, k=top_k)\n","        results = [\n","            {\"rank\": r + 1,\n","             \"score\": float(D[0][r]),\n","             \"doc_id\": self.doc_ids[I[0][r]]}\n","            for r in range(top_k)\n","        ]\n","        return results\n","\n","    def evaluate_questions(self, questions_dict, top_k=3):\n","        rows = []\n","        for q_id, q in tqdm(questions_dict.items(), desc=\"Evaluating questions\"):\n","                # Encode query and normalize\n","                query_vec = self._encode_query(q['question'])\n","\n","                # Search top-k documents\n","                D, I = self.index.search(query_vec, k=top_k)\n","                retrieved_ids = [self.doc_ids[idx] for idx in I[0]]\n","                retrieved_scores = [float(score) for score in D[0]]\n","\n","                # Compute ground-truth similarity score\n","                if true_id in self.doc_ids:\n","                    true_idx = self.doc_ids.index(true_id)\n","                    true_emb = self.embeddings[true_idx].reshape(1, -1)\n","                    correct_score = float(np.dot(query_vec, true_emb.T))\n","                else:\n","                    correct_score = None\n","\n","                # Find rank if ground truth appears in top-k\n","                correct_in_top_k = true_id in retrieved_ids\n","                rank = retrieved_ids.index(true_id) + 1 if correct_in_top_k else None\n","\n","                rows.append({\n","                    \"query\": q,\n","                    \"ground_truth\": true_id,\n","                    \"top_ids\": retrieved_ids,\n","                    \"top_scores\": retrieved_scores,\n","                    \"correct_in_top_k\": correct_in_top_k,\n","                    \"rank_of_correct\": rank,\n","                    \"ground_truth_score\": correct_score\n","                })\n","\n","        self.results_df = pd.DataFrame(rows)\n","        return self.results_df\n","\n","    # -------------------------------------------------------------------\n","    # 3️⃣ Compute Accuracy Metrics\n","    # -------------------------------------------------------------------\n","    def accuracy(self):\n","        \"\"\"Compute Top-k retrieval accuracy (fraction of queries whose true doc appears in top-k).\"\"\"\n","        if not hasattr(self, \"results_df\"):\n","            raise ValueError(\"Run evaluate_questions() first.\")\n","        return self.results_df[\"correct_in_top_k\"].mean()\n","\n","    # -------------------------------------------------------------------\n","    # 4️⃣ Save results as CSV\n","    # -------------------------------------------------------------------\n","    def save_results(self, path=\"retrieval_results.csv\"):\n","        if hasattr(self, \"results_df\"):\n","            self.results_df.to_csv(path, index=False)\n","            print(f\"✅ Saved retrieval results to {path}\")\n","        else:\n","            print(\"⚠️ No results to save. Run evaluate_questions() first.\")\n"],"metadata":{"id":"2w--QLn4znYk","executionInfo":{"status":"ok","timestamp":1762969688593,"user_tz":-330,"elapsed":37,"user":{"displayName":"Srinidhi","userId":"02160519943100045251"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Initialize evaluator\n","evaluator = EmbeddingSearchEvaluator()\n","results = evaluator.evaluate_full_scores(mahabharata_questions)\n","evaluator.save_full_scores()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CJvcUumb4jmr","executionInfo":{"status":"ok","timestamp":1762969719631,"user_tz":-330,"elapsed":26329,"user":{"displayName":"Srinidhi","userId":"02160519943100045251"}},"outputId":"b37a5bc4-3415-42c6-9c94-d86a03951750"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Loaded 2108 embeddings.\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating questions: 100%|██████████| 1536/1536 [00:19<00:00, 80.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["✅ Saved question–chapter scores to Retrieval Experiments/1.9/embedding_scores_1.json\n"]}]},{"cell_type":"code","source":["ground_truth = {}\n","for qid, q in mahabharata_questions.items():\n","  ground_truth[qid] = q[\"ground_truth\"]"],"metadata":{"id":"Qv6VwmjJJZ65","executionInfo":{"status":"ok","timestamp":1762969721811,"user_tz":-330,"elapsed":2,"user":{"displayName":"Srinidhi","userId":"02160519943100045251"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import math\n","\n","def evaluate_retrieval(scores, ground_truth, top_k=5):\n","    \"\"\"\n","    Evaluate retrieval performance using Precision@k, Recall@k, MRR, Hits@k, and nDCG@k.\n","    \"\"\"\n","    hits = []\n","    reciprocal_ranks = []\n","    precision_at_k = []\n","    recall_at_k = []\n","    ndcg_at_k = []\n","\n","    for qid, doc_scores in scores.items():\n","        if qid not in ground_truth:\n","            continue\n","\n","        true_doc = ground_truth[qid]\n","        ranked_docs = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)\n","        ranked_doc_ids = [d for d, _ in ranked_docs]\n","\n","        # Top-k\n","        topk_docs = ranked_doc_ids[:top_k]\n","\n","        # Hit@k\n","        hit = 1 if true_doc in topk_docs else 0\n","        hits.append(hit)\n","\n","        # Rank\n","        if true_doc in ranked_doc_ids:\n","            rank = ranked_doc_ids.index(true_doc) + 1\n","            reciprocal_ranks.append(1.0 / rank)\n","        else:\n","            reciprocal_ranks.append(0.0)\n","            rank = None\n","\n","        # Precision@k and Recall@k\n","        retrieved_relevant = 1 if true_doc in topk_docs else 0\n","        precision = retrieved_relevant / top_k\n","        recall = retrieved_relevant / 1  # only one relevant doc\n","        precision_at_k.append(precision)\n","        recall_at_k.append(recall)\n","\n","        # nDCG@k\n","        if rank and rank <= top_k:\n","            ndcg = 1 / math.log2(rank + 1)\n","        else:\n","            ndcg = 0.0\n","        ndcg_at_k.append(ndcg)\n","\n","    metrics = {\n","        f\"Precision@{top_k}\": np.mean(precision_at_k),\n","        f\"Recall@{top_k}\": np.mean(recall_at_k),\n","        f\"Hits@{top_k}\": np.mean(hits),\n","        f\"nDCG@{top_k}\": np.mean(ndcg_at_k),\n","        \"MRR\": np.mean(reciprocal_ranks)\n","    }\n","\n","    return metrics\n"],"metadata":{"id":"O9Q-WlLEK_lc","executionInfo":{"status":"ok","timestamp":1762969724814,"user_tz":-330,"elapsed":3,"user":{"displayName":"Srinidhi","userId":"02160519943100045251"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["scores = read_json('Retrieval Experiments/1.9/embedding_scores_1.json')\n","metrics = evaluate_retrieval(scores, ground_truth, top_k=3)\n","metrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-eSW6ry8LC1B","executionInfo":{"status":"ok","timestamp":1762969730557,"user_tz":-330,"elapsed":3697,"user":{"displayName":"Srinidhi","userId":"02160519943100045251"}},"outputId":"34411ab2-0a25-429b-ad7c-6f0a8341e34f"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Precision@3': np.float64(0.09678819444444442),\n"," 'Recall@3': np.float64(0.2903645833333333),\n"," 'Hits@3': np.float64(0.2903645833333333),\n"," 'nDCG@3': np.float64(0.23855858848121494),\n"," 'MRR': np.float64(0.2600468996410918)}"]},"metadata":{},"execution_count":16}]}]}